{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6559823b",
   "metadata": {},
   "source": [
    "# DFDC Dataset Sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84053b7c",
   "metadata": {},
   "source": [
    "This notebook is used to sample the full [DFDC](https://www.kaggle.com/c/deepfake-detection-challenge) dataset for deepfake detection research purposes. 100 deepfakes are randomly sampled with its corresponding original videos, resulting in a total of 200 videos (100 videos for each label).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16c16338-b562-4438-8146-9552a421f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedac2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"/mnt/e/datasets/DFDC\"\n",
    "TRAIN_DATA_DIR_PREFIX = \"dfdc_train\"\n",
    "METADATA_FILENAME = \"metadata.json\"\n",
    "\n",
    "SAMPLE_DIR = \"/mnt/e/samples/videos/DFDC\"\n",
    "SAMPLE_DEEPFAKE_DIR = os.path.join(SAMPLE_DIR, \"Deepfake\")\n",
    "SAMPLE_ORIGINAL_VID_DIR = os.path.join(SAMPLE_DIR, \"Original\")\n",
    "\n",
    "SAMPLE_SIZE = 100\n",
    "SAMPLE_LIST_PATH = \"dfdc-list.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377e497",
   "metadata": {},
   "source": [
    "## Deepfake and Real Video Sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30519482",
   "metadata": {},
   "source": [
    "Deepfakes are sampled by taking two random videos for each part of the dataset, of which there are 50 parts in total. The real video retrieved by taking the original video of each deepfake based on provided the metadata for each part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c1df582",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_part_dirs = [\n",
    "    dir_name\n",
    "    for dir_name in os.listdir(DATASET_DIR)\n",
    "    if TRAIN_DATA_DIR_PREFIX in dir_name\n",
    "]\n",
    "part_sample_size = SAMPLE_SIZE // len(dataset_part_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "91cb0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_original_vid_files = []\n",
    "sample_deepfake_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52ae8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vid_abs_path(filenames, part_dir):\n",
    "    return list(\n",
    "        map(\n",
    "            lambda filename: os.path.join(part_dir, filename),\n",
    "            filenames,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "25b213df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 100 original video files\n",
      "Sampled 100 deepfake files based on the sample original videos\n",
      "\n",
      "Sample original video:\n",
      "/mnt/e/datasets/DFDC/dfdc_train_part_0/doniqevxeg.mp4\n",
      "\n",
      "Sample deepfake:\n",
      "/mnt/e/datasets/DFDC/dfdc_train_part_0/nadprinqny.mp4\n"
     ]
    }
   ],
   "source": [
    "for part_dir in dataset_part_dirs:\n",
    "    part_fulldir = os.path.join(DATASET_DIR, part_dir)\n",
    "    metadata_filepath = os.path.join(part_fulldir, METADATA_FILENAME)\n",
    "\n",
    "    with open(metadata_filepath, \"r\") as metadata_file:\n",
    "        metadata = json.load(metadata_file)\n",
    "        keys = list(metadata.keys())\n",
    "        original_vids = [key for key in keys if metadata[key][\"label\"] == \"REAL\"]\n",
    "        sample_original_vids = random.sample(original_vids, part_sample_size)\n",
    "\n",
    "        # Sample deepfakes based on the sampled real videos\n",
    "        sample_deepfakes = []\n",
    "        for original_vid in sample_original_vids:\n",
    "            deepfake_filenames = [\n",
    "                key\n",
    "                for key in keys\n",
    "                if metadata[key][\"label\"] == \"FAKE\"\n",
    "                and metadata[key][\"original\"] == original_vid\n",
    "            ]\n",
    "            sample_deepfakes.append(random.choice(deepfake_filenames))\n",
    "\n",
    "        # Get absolute path for each sample videos\n",
    "        part_fulldir = os.path.join(\"/mnt/e/datasets/DFDC\", part_dir)\n",
    "        sample_original_vid_files.extend(\n",
    "            get_vid_abs_path(sample_original_vids, part_fulldir)\n",
    "        )\n",
    "        sample_deepfake_files.extend(get_vid_abs_path(sample_deepfakes, part_fulldir))\n",
    "\n",
    "print(f\"Sampled {len(sample_original_vid_files)} original video files\")\n",
    "print(\n",
    "    f\"Sampled {len(sample_deepfake_files)} deepfake files based on the sample original videos\"\n",
    ")\n",
    "\n",
    "print(\"\\nSample original video:\")\n",
    "print(sample_original_vid_files[0])\n",
    "print(\"\\nSample deepfake:\")\n",
    "print(sample_deepfake_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557da00",
   "metadata": {},
   "source": [
    "## Copy Sample to a Separate Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "27e15843",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in sample_original_vid_files:\n",
    "    if os.path.isfile(file_path):\n",
    "        shutil.copy(file_path, SAMPLE_ORIGINAL_VID_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "530f547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in sample_deepfake_files:\n",
    "    if os.path.isfile(file_path):\n",
    "        shutil.copy(file_path, SAMPLE_DEEPFAKE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eaa89d",
   "metadata": {},
   "source": [
    "## Create CSV File to List Sample Video Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba3683c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample videos filepath list generated in dfdc-list.csv\n"
     ]
    }
   ],
   "source": [
    "with open(SAMPLE_LIST_PATH, \"w\", newline=\"\") as sample_list_file:\n",
    "    header = [\"file\", \"label\"]\n",
    "    writer = csv.writer(sample_list_file)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for filename in sample_deepfake_files:\n",
    "        dataset_path = filename.split(\"/\")[-3:]\n",
    "        writer.writerow([\"/\".join(dataset_path), \"deepfake\"])\n",
    "\n",
    "    for filename in sample_original_vid_files:\n",
    "        dataset_path = filename.split(\"/\")[-3:]\n",
    "        writer.writerow([\"/\".join(dataset_path), \"real\"])\n",
    "\n",
    "    print(f\"Sample videos filepath list generated in {SAMPLE_LIST_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-tfx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
