{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fede4ef",
   "metadata": {
    "papermill": {
     "duration": 0.008023,
     "end_time": "2024-11-13T17:09:48.217683",
     "exception": false,
     "start_time": "2024-11-13T17:09:48.209660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparameter Tuning for Deepfake Detection CNN Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2c45c",
   "metadata": {
    "papermill": {
     "duration": 0.008178,
     "end_time": "2024-11-13T17:09:48.233328",
     "exception": false,
     "start_time": "2024-11-13T17:09:48.225150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook contains hyperparameter tuning process for CNN model development in deepfake detection. In this case, the tuned hyperparameters includes the number of convolutional layers including their filters and kernel sizes, number of dense layers including their units, dropout rate, and Adam optimizer's initial learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cbf8c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:09:48.250159Z",
     "iopub.status.busy": "2024-11-13T17:09:48.249259Z",
     "iopub.status.idle": "2024-11-13T17:10:01.789691Z",
     "shell.execute_reply": "2024-11-13T17:10:01.788856Z"
    },
    "papermill": {
     "duration": 13.551513,
     "end_time": "2024-11-13T17:10:01.792085",
     "exception": false,
     "start_time": "2024-11-13T17:09:48.240572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f4b3d",
   "metadata": {
    "papermill": {
     "duration": 0.007206,
     "end_time": "2024-11-13T17:10:01.806981",
     "exception": false,
     "start_time": "2024-11-13T17:10:01.799775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Dataset Directory Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b08a48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:01.823263Z",
     "iopub.status.busy": "2024-11-13T17:10:01.822375Z",
     "iopub.status.idle": "2024-11-13T17:10:01.827497Z",
     "shell.execute_reply": "2024-11-13T17:10:01.826663Z"
    },
    "papermill": {
     "duration": 0.015188,
     "end_time": "2024-11-13T17:10:01.829321",
     "exception": false,
     "start_time": "2024-11-13T17:10:01.814133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CDF_TRAIN_DIR = \"/kaggle/input/deepfake-detection-datasets/Celeb-DF-v2/Train\"\n",
    "CDF_VAL_DIR = \"/kaggle/input/deepfake-detection-datasets/Celeb-DF-v2/Val\"\n",
    "\n",
    "DF_TRAIN_DIR = \"/kaggle/input/deepfake-detection-datasets/DeeperForensics-1.0/Train\"\n",
    "DF_VAL_DIR = \"/kaggle/input/deepfake-detection-datasets/DeeperForensics-1.0/Val\"\n",
    "\n",
    "DFDC_TRAIN_DIR = \"/kaggle/input/deepfake-detection-datasets/DFDC/Train\"\n",
    "DFDC_VAL_DIR = \"/kaggle/input/deepfake-detection-datasets/DFDC/Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0baf59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:01.845285Z",
     "iopub.status.busy": "2024-11-13T17:10:01.845011Z",
     "iopub.status.idle": "2024-11-13T17:10:01.852123Z",
     "shell.execute_reply": "2024-11-13T17:10:01.851232Z"
    },
    "papermill": {
     "duration": 0.017261,
     "end_time": "2024-11-13T17:10:01.853962",
     "exception": false,
     "start_time": "2024-11-13T17:10:01.836701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_train_deepfake_dir = os.path.join(CDF_TRAIN_DIR, \"Deepfake\")\n",
    "cdf_train_real_vid_dir = os.path.join(CDF_TRAIN_DIR, \"Original\")\n",
    "cdf_val_deepfake_dir = os.path.join(CDF_VAL_DIR, \"Deepfake\")\n",
    "cdf_val_real_vid_dir = os.path.join(CDF_VAL_DIR, \"Original\")\n",
    "\n",
    "df_train_deepfake_dir = os.path.join(DF_TRAIN_DIR, \"Deepfake\")\n",
    "df_train_real_vid_dir = os.path.join(DF_TRAIN_DIR, \"Original\")\n",
    "df_val_deepfake_dir = os.path.join(DF_VAL_DIR, \"Deepfake\")\n",
    "df_val_real_vid_dir = os.path.join(DF_VAL_DIR, \"Original\")\n",
    "\n",
    "dfdc_train_deepfake_dir = os.path.join(DFDC_TRAIN_DIR, \"Deepfake\")\n",
    "dfdc_train_real_vid_dir = os.path.join(DFDC_TRAIN_DIR, \"Original\")\n",
    "dfdc_val_deepfake_dir = os.path.join(DFDC_VAL_DIR, \"Deepfake\")\n",
    "dfdc_val_real_vid_dir = os.path.join(DFDC_VAL_DIR, \"Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68a029a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:01.869945Z",
     "iopub.status.busy": "2024-11-13T17:10:01.869672Z",
     "iopub.status.idle": "2024-11-13T17:10:05.810177Z",
     "shell.execute_reply": "2024-11-13T17:10:05.809076Z"
    },
    "papermill": {
     "duration": 3.951076,
     "end_time": "2024-11-13T17:10:05.812413",
     "exception": false,
     "start_time": "2024-11-13T17:10:01.861337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded:\n",
      "\n",
      "Celeb-DF-v2 (Train Split)\n",
      " - 7000 deepfake frames\n",
      " - 7000 real vid frames\n",
      "Celeb-DF-v2 (Val Split)\n",
      " - 1000 deepfake frames\n",
      " - 1000 real vid frames\n",
      "\n",
      "DeeperForensics-1.0 (Train Split)\n",
      " - 7000 deepfake frames\n",
      " - 7000 real vid frames\n",
      "DeeperForensics-1.0 (Val Split)\n",
      " - 1000 deepfake frames\n",
      " - 1000 real vid frames\n",
      "\n",
      "Deepfake Detection Challenge (Train Split)\n",
      " - 7000 deepfake frames\n",
      " - 7000 real vid frames\n",
      "Deepfake Detection Challenge (Val Split)\n",
      " - 1000 deepfake frames\n",
      " - 1000 real vid frames\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset loaded:\")\n",
    "\n",
    "print(\"\\nCeleb-DF-v2 (Train Split)\")\n",
    "print(f\" - {len(os.listdir(cdf_train_deepfake_dir))} deepfake frames\")\n",
    "print(f\" - {len(os.listdir(cdf_train_real_vid_dir))} real vid frames\")\n",
    "print(\"Celeb-DF-v2 (Val Split)\")\n",
    "print(f\" - {len(os.listdir(cdf_val_deepfake_dir))} deepfake frames\")\n",
    "print(f\" - {len(os.listdir(cdf_val_real_vid_dir))} real vid frames\")\n",
    "\n",
    "print(\"\\nDeeperForensics-1.0 (Train Split)\")\n",
    "print(f\" - {len(os.listdir(df_train_deepfake_dir))} deepfake frames\")\n",
    "print(f\" - {len(os.listdir(df_train_real_vid_dir))} real vid frames\")\n",
    "print(\"DeeperForensics-1.0 (Val Split)\")\n",
    "print(f\" - {len(os.listdir(df_val_deepfake_dir))} deepfake frames\")\n",
    "print(f\" - {len(os.listdir(df_val_real_vid_dir))} real vid frames\")\n",
    "\n",
    "print(\"\\nDeepfake Detection Challenge (Train Split)\")\n",
    "print(f\" - {len(os.listdir(dfdc_train_deepfake_dir))} deepfake frames\")\n",
    "print(f\" - {len(os.listdir(dfdc_train_real_vid_dir))} real vid frames\")\n",
    "print(\"Deepfake Detection Challenge (Val Split)\")\n",
    "print(f\" - {len(os.listdir(dfdc_val_deepfake_dir))} deepfake frames\")\n",
    "print(f\" - {len(os.listdir(dfdc_val_real_vid_dir))} real vid frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76797d8b",
   "metadata": {
    "papermill": {
     "duration": 0.008475,
     "end_time": "2024-11-13T17:10:05.829764",
     "exception": false,
     "start_time": "2024-11-13T17:10:05.821289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Combined Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3fa4f",
   "metadata": {
    "papermill": {
     "duration": 0.0085,
     "end_time": "2024-11-13T17:10:05.846890",
     "exception": false,
     "start_time": "2024-11-13T17:10:05.838390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For hyperparameter tuning purposes, the three datasets are combined into a new set for each train and validation split. For the train split, the full dataset will be sampled, taking only 20% for each dataset to reduce computational cost in the hyperparameter tuning process. The validation split is also sampled, taking only 40% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584dd9e",
   "metadata": {
    "papermill": {
     "duration": 0.008302,
     "end_time": "2024-11-13T17:10:05.863709",
     "exception": false,
     "start_time": "2024-11-13T17:10:05.855407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get Full Filepath for Each Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4c28c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:05.882865Z",
     "iopub.status.busy": "2024-11-13T17:10:05.882071Z",
     "iopub.status.idle": "2024-11-13T17:10:05.887052Z",
     "shell.execute_reply": "2024-11-13T17:10:05.886175Z"
    },
    "papermill": {
     "duration": 0.016667,
     "end_time": "2024-11-13T17:10:05.888914",
     "exception": false,
     "start_time": "2024-11-13T17:10:05.872247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_filepath_from_dir(dir_path):\n",
    "    return [\n",
    "        os.path.join(dir_path, filename) for filename in sorted(os.listdir(dir_path))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac818235",
   "metadata": {
    "papermill": {
     "duration": 0.008427,
     "end_time": "2024-11-13T17:10:05.905833",
     "exception": false,
     "start_time": "2024-11-13T17:10:05.897406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb79d42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:05.924621Z",
     "iopub.status.busy": "2024-11-13T17:10:05.923891Z",
     "iopub.status.idle": "2024-11-13T17:10:06.035161Z",
     "shell.execute_reply": "2024-11-13T17:10:06.034167Z"
    },
    "papermill": {
     "duration": 0.122988,
     "end_time": "2024-11-13T17:10:06.037462",
     "exception": false,
     "start_time": "2024-11-13T17:10:05.914474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_train_deepfake_filepaths = get_filepath_from_dir(cdf_train_deepfake_dir)\n",
    "cdf_train_real_vid_filepaths = get_filepath_from_dir(cdf_train_real_vid_dir)\n",
    "\n",
    "df_train_deepfake_filepaths = get_filepath_from_dir(df_train_deepfake_dir)\n",
    "df_train_real_vid_filepaths = get_filepath_from_dir(df_train_real_vid_dir)\n",
    "\n",
    "dfdc_train_deepfake_filepaths = get_filepath_from_dir(dfdc_train_deepfake_dir)\n",
    "dfdc_train_real_vid_filepaths = get_filepath_from_dir(dfdc_train_real_vid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd31167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.056497Z",
     "iopub.status.busy": "2024-11-13T17:10:06.055903Z",
     "iopub.status.idle": "2024-11-13T17:10:06.062524Z",
     "shell.execute_reply": "2024-11-13T17:10:06.061583Z"
    },
    "papermill": {
     "duration": 0.01818,
     "end_time": "2024-11-13T17:10:06.064500",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.046320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample the 20% data of the full train split\n",
    "\n",
    "train_sample_size_per_dataset = 0.2 * len(cdf_train_deepfake_filepaths)\n",
    "train_sample_size_per_label = int(train_sample_size_per_dataset / 2)\n",
    "\n",
    "cdf_train_deepfake_filepaths = cdf_train_deepfake_filepaths[:train_sample_size_per_label]\n",
    "cdf_train_real_vid_filepaths = cdf_train_real_vid_filepaths[:train_sample_size_per_label]\n",
    "\n",
    "df_train_deepfake_filepaths = df_train_deepfake_filepaths[:train_sample_size_per_label]\n",
    "df_train_real_vid_filepaths = df_train_real_vid_filepaths[:train_sample_size_per_label]\n",
    "\n",
    "dfdc_train_deepfake_filepaths = dfdc_train_deepfake_filepaths[:train_sample_size_per_label]\n",
    "dfdc_train_real_vid_filepaths = dfdc_train_real_vid_filepaths[:train_sample_size_per_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45dc47",
   "metadata": {
    "papermill": {
     "duration": 0.008444,
     "end_time": "2024-11-13T17:10:06.081732",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.073288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20074c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.100114Z",
     "iopub.status.busy": "2024-11-13T17:10:06.099598Z",
     "iopub.status.idle": "2024-11-13T17:10:06.120663Z",
     "shell.execute_reply": "2024-11-13T17:10:06.119980Z"
    },
    "papermill": {
     "duration": 0.03242,
     "end_time": "2024-11-13T17:10:06.122613",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.090193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdf_val_deepfake_filepaths = get_filepath_from_dir(cdf_val_deepfake_dir)\n",
    "cdf_val_real_vid_filepaths = get_filepath_from_dir(cdf_val_real_vid_dir)\n",
    "\n",
    "df_val_deepfake_filepaths = get_filepath_from_dir(df_val_deepfake_dir)\n",
    "df_val_real_vid_filepaths = get_filepath_from_dir(df_val_real_vid_dir)\n",
    "\n",
    "dfdc_val_deepfake_filepaths = get_filepath_from_dir(dfdc_val_deepfake_dir)\n",
    "dfdc_val_real_vid_filepaths = get_filepath_from_dir(dfdc_val_real_vid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67f03c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.141256Z",
     "iopub.status.busy": "2024-11-13T17:10:06.140967Z",
     "iopub.status.idle": "2024-11-13T17:10:06.146219Z",
     "shell.execute_reply": "2024-11-13T17:10:06.145412Z"
    },
    "papermill": {
     "duration": 0.016654,
     "end_time": "2024-11-13T17:10:06.148094",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.131440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample the 40% data of the full train split\n",
    "\n",
    "val_sample_size_per_dataset = 0.4 * len(cdf_val_deepfake_filepaths)\n",
    "val_sample_size_per_label = int(val_sample_size_per_dataset / 2)\n",
    "\n",
    "cdf_val_deepfake_filepaths = cdf_val_deepfake_filepaths[:val_sample_size_per_label]\n",
    "cdf_val_real_vid_filepaths = cdf_val_real_vid_filepaths[:val_sample_size_per_label]\n",
    "\n",
    "df_val_deepfake_filepaths = df_val_deepfake_filepaths[:val_sample_size_per_label]\n",
    "df_val_real_vid_filepaths = df_val_real_vid_filepaths[:val_sample_size_per_label]\n",
    "\n",
    "dfdc_val_deepfake_filepaths = dfdc_val_deepfake_filepaths[:val_sample_size_per_label]\n",
    "dfdc_val_real_vid_filepaths = dfdc_val_real_vid_filepaths[:val_sample_size_per_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9737e0",
   "metadata": {
    "papermill": {
     "duration": 0.008536,
     "end_time": "2024-11-13T17:10:06.165195",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.156659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Combine Dataset in a List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2eb1f3",
   "metadata": {
    "papermill": {
     "duration": 0.008566,
     "end_time": "2024-11-13T17:10:06.182326",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.173760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ad2dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.200666Z",
     "iopub.status.busy": "2024-11-13T17:10:06.200376Z",
     "iopub.status.idle": "2024-11-13T17:10:06.207978Z",
     "shell.execute_reply": "2024-11-13T17:10:06.207142Z"
    },
    "papermill": {
     "duration": 0.018987,
     "end_time": "2024-11-13T17:10:06.210002",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.191015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 4200 frames in total\n"
     ]
    }
   ],
   "source": [
    "combined_train_filepaths = []\n",
    "combined_train_filepaths += cdf_train_deepfake_filepaths + cdf_train_real_vid_filepaths\n",
    "combined_train_filepaths += df_train_deepfake_filepaths + df_train_real_vid_filepaths\n",
    "combined_train_filepaths += dfdc_train_deepfake_filepaths + dfdc_train_real_vid_filepaths\n",
    "\n",
    "# Get labels for each file based on their directory name\n",
    "combined_train_labels = [\n",
    "    filepath.split(\"/\")[-2]\n",
    "    for filepath in combined_train_filepaths\n",
    "]\n",
    "\n",
    "print(f\"Got {len(combined_train_filepaths)} frames in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b158a3d",
   "metadata": {
    "papermill": {
     "duration": 0.008759,
     "end_time": "2024-11-13T17:10:06.227811",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.219052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d11482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.246466Z",
     "iopub.status.busy": "2024-11-13T17:10:06.246166Z",
     "iopub.status.idle": "2024-11-13T17:10:06.252224Z",
     "shell.execute_reply": "2024-11-13T17:10:06.251388Z"
    },
    "papermill": {
     "duration": 0.017833,
     "end_time": "2024-11-13T17:10:06.254397",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.236564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1200 frames in total\n"
     ]
    }
   ],
   "source": [
    "combined_val_filepaths = []\n",
    "combined_val_filepaths += cdf_val_deepfake_filepaths + cdf_val_real_vid_filepaths\n",
    "combined_val_filepaths += df_val_deepfake_filepaths + df_val_real_vid_filepaths\n",
    "combined_val_filepaths += dfdc_val_deepfake_filepaths + dfdc_val_real_vid_filepaths\n",
    "\n",
    "# Get labels for each file based on their directory name\n",
    "combined_val_labels = [\n",
    "    filepath.split(\"/\")[-2]\n",
    "    for filepath in combined_val_filepaths\n",
    "]\n",
    "\n",
    "print(f\"Got {len(combined_val_filepaths)} frames in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffa34b",
   "metadata": {
    "papermill": {
     "duration": 0.008647,
     "end_time": "2024-11-13T17:10:06.271945",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.263298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create a DataFrame to Store the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4363c",
   "metadata": {
    "papermill": {
     "duration": 0.008776,
     "end_time": "2024-11-13T17:10:06.289538",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.280762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fd35294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.308521Z",
     "iopub.status.busy": "2024-11-13T17:10:06.308171Z",
     "iopub.status.idle": "2024-11-13T17:10:06.328391Z",
     "shell.execute_reply": "2024-11-13T17:10:06.327533Z"
    },
    "papermill": {
     "duration": 0.031937,
     "end_time": "2024-11-13T17:10:06.330328",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.298391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath     label\n",
       "0  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake\n",
       "1  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake\n",
       "2  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake\n",
       "3  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake\n",
       "4  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_train_dataset = pd.DataFrame({\n",
    "    \"filepath\": combined_train_filepaths,\n",
    "    \"label\": combined_train_labels\n",
    "})\n",
    "\n",
    "tuning_train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3d455",
   "metadata": {
    "papermill": {
     "duration": 0.009028,
     "end_time": "2024-11-13T17:10:06.348649",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.339621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b40ae39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.368543Z",
     "iopub.status.busy": "2024-11-13T17:10:06.367940Z",
     "iopub.status.idle": "2024-11-13T17:10:06.377529Z",
     "shell.execute_reply": "2024-11-13T17:10:06.376719Z"
    },
    "papermill": {
     "duration": 0.021912,
     "end_time": "2024-11-13T17:10:06.379644",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.357732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/deepfake-detection-datasets/Cele...</td>\n",
       "      <td>Deepfake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath     label\n",
       "0  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake\n",
       "1  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake\n",
       "2  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake\n",
       "3  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake\n",
       "4  /kaggle/input/deepfake-detection-datasets/Cele...  Deepfake"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_val_dataset = pd.DataFrame({\n",
    "    \"filepath\": combined_val_filepaths,\n",
    "    \"label\": combined_val_labels\n",
    "})\n",
    "\n",
    "tuning_val_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec1164",
   "metadata": {
    "papermill": {
     "duration": 0.009253,
     "end_time": "2024-11-13T17:10:06.398274",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.389021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb95d2ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.418805Z",
     "iopub.status.busy": "2024-11-13T17:10:06.418207Z",
     "iopub.status.idle": "2024-11-13T17:10:06.423382Z",
     "shell.execute_reply": "2024-11-13T17:10:06.422562Z"
    },
    "papermill": {
     "duration": 0.017543,
     "end_time": "2024-11-13T17:10:06.425279",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.407736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_generator(dataset_df):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    generator = datagen.flow_from_dataframe(\n",
    "        dataset_df,\n",
    "        x_col=\"filepath\",\n",
    "        y_col=\"label\",\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        color_mode=\"rgb\",\n",
    "        class_mode=\"binary\",\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b21fe006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:06.445739Z",
     "iopub.status.busy": "2024-11-13T17:10:06.445132Z",
     "iopub.status.idle": "2024-11-13T17:10:18.614901Z",
     "shell.execute_reply": "2024-11-13T17:10:18.613878Z"
    },
    "papermill": {
     "duration": 12.182433,
     "end_time": "2024-11-13T17:10:18.617150",
     "exception": false,
     "start_time": "2024-11-13T17:10:06.434717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image generator created:\n",
      "Found 4200 validated image filenames belonging to 2 classes.\n",
      "\n",
      "Validation image generator created:\n",
      "Found 1200 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Train image generator created:\")\n",
    "train_generator = create_generator(tuning_train_dataset)\n",
    "\n",
    "print(\"\\nValidation image generator created:\")\n",
    "val_generator = create_generator(tuning_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86366004",
   "metadata": {
    "papermill": {
     "duration": 0.009848,
     "end_time": "2024-11-13T17:10:18.637107",
     "exception": false,
     "start_time": "2024-11-13T17:10:18.627259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Builder Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "909663fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:18.658739Z",
     "iopub.status.busy": "2024-11-13T17:10:18.657913Z",
     "iopub.status.idle": "2024-11-13T17:10:18.862603Z",
     "shell.execute_reply": "2024-11-13T17:10:18.861735Z"
    },
    "papermill": {
     "duration": 0.217578,
     "end_time": "2024-11-13T17:10:18.864601",
     "exception": false,
     "start_time": "2024-11-13T17:10:18.647023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    conv_layers = hp.Int(\"conv_layers\", min_value=3, max_value=7)\n",
    "    conv_layer_filters = [\n",
    "        hp.Int(f\"conv_{i+1}_filters\", min_value=32, max_value=256, step=32)\n",
    "        for i in range(conv_layers)\n",
    "    ]\n",
    "    conv_layer_kernel_size = [\n",
    "        hp.Int(f\"conv_{i+1}_kernel_size\", min_value=3, max_value=5, step=2)\n",
    "        for i in range(conv_layers)\n",
    "    ]\n",
    "    dense_layers = hp.Int(\"dense_layers\", min_value=2, max_value=7)\n",
    "    dense_layer_units = [\n",
    "        hp.Int(f\"dense_{i+1}_layer_units\", min_value=32, max_value=128, step=32)\n",
    "        for i in range(dense_layers)\n",
    "    ]\n",
    "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.4, max_value=0.8, step=0.1)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-5, max_value=1e-2, step=10)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(128, 128, 3)))\n",
    "\n",
    "    for i in range(conv_layers):\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv2D(\n",
    "                conv_layer_filters[i],\n",
    "                (conv_layer_kernel_size[i], conv_layer_kernel_size[i]),\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "            )\n",
    "        )\n",
    "        model.add(tf.keras.layers.MaxPooling2D(2, 2))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    for i in range(dense_layers):\n",
    "        model.add(tf.keras.layers.Dense(dense_layer_units[i], activation=\"relu\"))\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e8da0",
   "metadata": {
    "papermill": {
     "duration": 0.009941,
     "end_time": "2024-11-13T17:10:18.884811",
     "exception": false,
     "start_time": "2024-11-13T17:10:18.874870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Search for the Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7afaf48d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:18.906238Z",
     "iopub.status.busy": "2024-11-13T17:10:18.905699Z",
     "iopub.status.idle": "2024-11-13T17:10:19.731917Z",
     "shell.execute_reply": "2024-11-13T17:10:19.731123Z"
    },
    "papermill": {
     "duration": 0.839515,
     "end_time": "2024-11-13T17:10:19.734272",
     "exception": false,
     "start_time": "2024-11-13T17:10:18.894757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective=\"val_accuracy\",\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory=\"tuner-result\",\n",
    "                     project_name=\"cnn-best-hp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "014c8216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:19.756334Z",
     "iopub.status.busy": "2024-11-13T17:10:19.756017Z",
     "iopub.status.idle": "2024-11-13T17:10:19.760486Z",
     "shell.execute_reply": "2024-11-13T17:10:19.759595Z"
    },
    "papermill": {
     "duration": 0.017712,
     "end_time": "2024-11-13T17:10:19.762390",
     "exception": false,
     "start_time": "2024-11-13T17:10:19.744678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
    "                                                  patience=5,\n",
    "                                                  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d28f42fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:10:19.783666Z",
     "iopub.status.busy": "2024-11-13T17:10:19.783391Z",
     "iopub.status.idle": "2024-11-13T17:47:13.090582Z",
     "shell.execute_reply": "2024-11-13T17:47:13.089439Z"
    },
    "papermill": {
     "duration": 2213.406439,
     "end_time": "2024-11-13T17:47:13.178891",
     "exception": false,
     "start_time": "2024-11-13T17:10:19.772452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 42s]\n",
      "val_accuracy: 0.6000000238418579\n",
      "\n",
      "Best val_accuracy So Far: 0.7691666483879089\n",
      "Total elapsed time: 00h 36m 53s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_generator,\n",
    "             validation_data=val_generator,\n",
    "             verbose=1,\n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16c0662d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T17:47:13.202251Z",
     "iopub.status.busy": "2024-11-13T17:47:13.201474Z",
     "iopub.status.idle": "2024-11-13T17:47:13.212248Z",
     "shell.execute_reply": "2024-11-13T17:47:13.211372Z"
    },
    "papermill": {
     "duration": 0.026292,
     "end_time": "2024-11-13T17:47:13.215607",
     "exception": false,
     "start_time": "2024-11-13T17:47:13.189315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tuner-result/cnn-best-hp\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0024 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 6\n",
      "conv_1_filters: 256\n",
      "conv_2_filters: 32\n",
      "conv_3_filters: 160\n",
      "conv_1_kernel_size: 3\n",
      "conv_2_kernel_size: 5\n",
      "conv_3_kernel_size: 5\n",
      "dense_layers: 6\n",
      "dense_1_layer_units: 128\n",
      "dense_2_layer_units: 96\n",
      "dropout_rate: 0.6000000000000001\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 96\n",
      "dense_4_layer_units: 96\n",
      "dense_5_layer_units: 64\n",
      "conv_4_filters: 128\n",
      "conv_4_kernel_size: 5\n",
      "conv_5_filters: 192\n",
      "conv_6_filters: 128\n",
      "conv_7_filters: 224\n",
      "conv_5_kernel_size: 5\n",
      "conv_6_kernel_size: 5\n",
      "conv_7_kernel_size: 3\n",
      "dense_6_layer_units: 128\n",
      "dense_7_layer_units: 32\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0023\n",
      "Score: 0.7691666483879089\n",
      "\n",
      "Trial 0026 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 7\n",
      "conv_1_filters: 96\n",
      "conv_2_filters: 192\n",
      "conv_3_filters: 96\n",
      "conv_1_kernel_size: 5\n",
      "conv_2_kernel_size: 5\n",
      "conv_3_kernel_size: 3\n",
      "dense_layers: 6\n",
      "dense_1_layer_units: 128\n",
      "dense_2_layer_units: 128\n",
      "dropout_rate: 0.4\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 96\n",
      "dense_4_layer_units: 96\n",
      "dense_5_layer_units: 96\n",
      "conv_4_filters: 256\n",
      "conv_4_kernel_size: 5\n",
      "conv_5_filters: 64\n",
      "conv_6_filters: 64\n",
      "conv_7_filters: 160\n",
      "conv_5_kernel_size: 5\n",
      "conv_6_kernel_size: 3\n",
      "conv_7_kernel_size: 3\n",
      "dense_6_layer_units: 32\n",
      "dense_7_layer_units: 32\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.7483333349227905\n",
      "\n",
      "Trial 0028 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 3\n",
      "conv_1_filters: 32\n",
      "conv_2_filters: 160\n",
      "conv_3_filters: 128\n",
      "conv_1_kernel_size: 5\n",
      "conv_2_kernel_size: 5\n",
      "conv_3_kernel_size: 3\n",
      "dense_layers: 2\n",
      "dense_1_layer_units: 128\n",
      "dense_2_layer_units: 128\n",
      "dropout_rate: 0.6000000000000001\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 128\n",
      "dense_4_layer_units: 128\n",
      "dense_5_layer_units: 64\n",
      "conv_4_filters: 160\n",
      "conv_4_kernel_size: 3\n",
      "conv_5_filters: 96\n",
      "conv_6_filters: 64\n",
      "conv_7_filters: 192\n",
      "conv_5_kernel_size: 3\n",
      "conv_6_kernel_size: 5\n",
      "conv_7_kernel_size: 3\n",
      "dense_6_layer_units: 96\n",
      "dense_7_layer_units: 128\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.7316666841506958\n",
      "\n",
      "Trial 0025 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 7\n",
      "conv_1_filters: 224\n",
      "conv_2_filters: 256\n",
      "conv_3_filters: 64\n",
      "conv_1_kernel_size: 5\n",
      "conv_2_kernel_size: 5\n",
      "conv_3_kernel_size: 3\n",
      "dense_layers: 5\n",
      "dense_1_layer_units: 96\n",
      "dense_2_layer_units: 96\n",
      "dropout_rate: 0.5\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 32\n",
      "dense_4_layer_units: 96\n",
      "dense_5_layer_units: 64\n",
      "conv_4_filters: 256\n",
      "conv_4_kernel_size: 5\n",
      "conv_5_filters: 64\n",
      "conv_6_filters: 128\n",
      "conv_7_filters: 64\n",
      "conv_5_kernel_size: 3\n",
      "conv_6_kernel_size: 3\n",
      "conv_7_kernel_size: 3\n",
      "dense_6_layer_units: 96\n",
      "dense_7_layer_units: 128\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 0018\n",
      "Score: 0.6583333611488342\n",
      "\n",
      "Trial 0023 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 6\n",
      "conv_1_filters: 256\n",
      "conv_2_filters: 32\n",
      "conv_3_filters: 160\n",
      "conv_1_kernel_size: 3\n",
      "conv_2_kernel_size: 5\n",
      "conv_3_kernel_size: 5\n",
      "dense_layers: 6\n",
      "dense_1_layer_units: 128\n",
      "dense_2_layer_units: 96\n",
      "dropout_rate: 0.6000000000000001\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 96\n",
      "dense_4_layer_units: 96\n",
      "dense_5_layer_units: 64\n",
      "conv_4_filters: 128\n",
      "conv_4_kernel_size: 5\n",
      "conv_5_filters: 192\n",
      "conv_6_filters: 128\n",
      "conv_7_filters: 224\n",
      "conv_5_kernel_size: 5\n",
      "conv_6_kernel_size: 5\n",
      "conv_7_kernel_size: 3\n",
      "dense_6_layer_units: 128\n",
      "dense_7_layer_units: 32\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.6391666531562805\n",
      "\n",
      "Trial 0029 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 4\n",
      "conv_1_filters: 224\n",
      "conv_2_filters: 128\n",
      "conv_3_filters: 32\n",
      "conv_1_kernel_size: 5\n",
      "conv_2_kernel_size: 5\n",
      "conv_3_kernel_size: 3\n",
      "dense_layers: 4\n",
      "dense_1_layer_units: 96\n",
      "dense_2_layer_units: 128\n",
      "dropout_rate: 0.4\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 96\n",
      "dense_4_layer_units: 96\n",
      "dense_5_layer_units: 128\n",
      "conv_4_filters: 256\n",
      "conv_4_kernel_size: 3\n",
      "conv_5_filters: 192\n",
      "conv_6_filters: 224\n",
      "conv_7_filters: 160\n",
      "conv_5_kernel_size: 3\n",
      "conv_6_kernel_size: 3\n",
      "conv_7_kernel_size: 5\n",
      "dense_6_layer_units: 64\n",
      "dense_7_layer_units: 128\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.6000000238418579\n",
      "\n",
      "Trial 0018 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 7\n",
      "conv_1_filters: 224\n",
      "conv_2_filters: 256\n",
      "conv_3_filters: 64\n",
      "conv_1_kernel_size: 5\n",
      "conv_2_kernel_size: 5\n",
      "conv_3_kernel_size: 3\n",
      "dense_layers: 5\n",
      "dense_1_layer_units: 96\n",
      "dense_2_layer_units: 96\n",
      "dropout_rate: 0.5\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 32\n",
      "dense_4_layer_units: 96\n",
      "dense_5_layer_units: 64\n",
      "conv_4_filters: 256\n",
      "conv_4_kernel_size: 5\n",
      "conv_5_filters: 64\n",
      "conv_6_filters: 128\n",
      "conv_7_filters: 64\n",
      "conv_5_kernel_size: 3\n",
      "conv_6_kernel_size: 3\n",
      "conv_7_kernel_size: 3\n",
      "dense_6_layer_units: 96\n",
      "dense_7_layer_units: 128\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.5799999833106995\n",
      "\n",
      "Trial 0004 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 7\n",
      "conv_1_filters: 32\n",
      "conv_2_filters: 96\n",
      "conv_3_filters: 128\n",
      "conv_1_kernel_size: 3\n",
      "conv_2_kernel_size: 3\n",
      "conv_3_kernel_size: 5\n",
      "dense_layers: 3\n",
      "dense_1_layer_units: 128\n",
      "dense_2_layer_units: 32\n",
      "dropout_rate: 0.6000000000000001\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 32\n",
      "dense_4_layer_units: 128\n",
      "dense_5_layer_units: 32\n",
      "conv_4_filters: 32\n",
      "conv_4_kernel_size: 3\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "conv_5_filters: 32\n",
      "conv_6_filters: 32\n",
      "conv_7_filters: 32\n",
      "conv_5_kernel_size: 3\n",
      "conv_6_kernel_size: 3\n",
      "conv_7_kernel_size: 3\n",
      "Score: 0.5625\n",
      "\n",
      "Trial 0012 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 7\n",
      "conv_1_filters: 32\n",
      "conv_2_filters: 96\n",
      "conv_3_filters: 128\n",
      "conv_1_kernel_size: 3\n",
      "conv_2_kernel_size: 3\n",
      "conv_3_kernel_size: 5\n",
      "dense_layers: 3\n",
      "dense_1_layer_units: 128\n",
      "dense_2_layer_units: 32\n",
      "dropout_rate: 0.6000000000000001\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 32\n",
      "dense_4_layer_units: 128\n",
      "dense_5_layer_units: 32\n",
      "conv_4_filters: 32\n",
      "conv_4_kernel_size: 3\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 3\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "conv_5_filters: 32\n",
      "conv_6_filters: 32\n",
      "conv_7_filters: 32\n",
      "conv_5_kernel_size: 3\n",
      "conv_6_kernel_size: 3\n",
      "conv_7_kernel_size: 3\n",
      "tuner/trial_id: 0004\n",
      "dense_6_layer_units: 32\n",
      "dense_7_layer_units: 32\n",
      "Score: 0.5458333492279053\n",
      "\n",
      "Trial 0016 summary\n",
      "Hyperparameters:\n",
      "conv_layers: 7\n",
      "conv_1_filters: 32\n",
      "conv_2_filters: 96\n",
      "conv_3_filters: 128\n",
      "conv_1_kernel_size: 3\n",
      "conv_2_kernel_size: 3\n",
      "conv_3_kernel_size: 5\n",
      "dense_layers: 3\n",
      "dense_1_layer_units: 128\n",
      "dense_2_layer_units: 32\n",
      "dropout_rate: 0.6000000000000001\n",
      "learning_rate: 1e-05\n",
      "dense_3_layer_units: 32\n",
      "dense_4_layer_units: 128\n",
      "dense_5_layer_units: 32\n",
      "conv_4_filters: 32\n",
      "conv_4_kernel_size: 3\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "conv_5_filters: 32\n",
      "conv_6_filters: 32\n",
      "conv_7_filters: 32\n",
      "conv_5_kernel_size: 3\n",
      "conv_6_kernel_size: 3\n",
      "conv_7_kernel_size: 3\n",
      "tuner/trial_id: 0012\n",
      "dense_6_layer_units: 32\n",
      "dense_7_layer_units: 32\n",
      "Score: 0.5416666865348816\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6006079,
     "sourceId": 9876733,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2251.570424,
   "end_time": "2024-11-13T17:47:17.080987",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-13T17:09:45.510563",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
